import os
import pandas as pd
import numpy as np
import sklearn
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from classification_function import kfold
from tqdm import tqdm # show progress bar
import time

def get_permutation_p(symptom_permu_file,no_permu,symptom,X,Y,all_y_results):
    results_int_permu = []
    results_ext_permu = []
    for permu in tqdm(range(no_permu)):
        Y_permu = np.copy(Y)
        np.random.shuffle(Y_permu)
        space = {'max_features': list(range(1,16))}
        cv_outer = KFold(n_splits=10, random_state=0, shuffle=True)
        outer_results = list()
        inner_results = list()
        for train_ix, test_ix in cv_outer.split(X):
            X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]
            y_train, y_test = pd.Series(Y_permu).iloc[train_ix], pd.Series(Y_permu).iloc[test_ix]
            cv_inner = KFold(n_splits=5, random_state=0, shuffle=True)
            model = RandomForestRegressor(random_state=0, n_jobs=27)
            search = GridSearchCV(model, space, scoring='r2', cv=cv_inner, refit=True, n_jobs=27)
            result = search.fit(X_train, y_train)
            # get the best performing model fit on the whole training set
            best_model = result.best_estimator_
            #best_score_: Mean cross-validated score of the best_estimator
            inner_results.append(result.best_score_)
            # evaluate model on the hold out dataset, get the R2 of the best_estimator
            yhat = best_model.predict(X_test)
            # evaluate the model, R2
            r2 = sklearn.metrics.r2_score(y_test, yhat)
            # store the result
            outer_results.append(r2)
        # summarize the estimated performance of the model
        results_int_permu.append(np.mean(inner_results))
        results_ext_permu.append(np.mean(outer_results))
        #save this to the file
        symptom_permu_file.loc[len(symptom_permu_file.index)] = [symptom, np.mean(inner_results), np.mean(outer_results)]
        os.chdir('your data path')
        symptom_permu_file.to_csv(symptom+"_permutation.csv")
    
    score_int = float(all_y_results[all_y_results["Symptoms"] == symptom]["inner_results"])
    score_ext = float(all_y_results[all_y_results["Symptoms"] == symptom]["outer_results"])
    
    return [results_int_permu, results_ext_permu, score_int, score_ext]

def get_permutation_p_lasso(no_permu,X,Y,inner_mean,outer_mean):
    svm_permu_file = pd.read_csv("lasso_permutation_collections_selfesteem.csv")
    if len(svm_permu_file.columns) > 2:
        svm_permu_file = svm_permu_file.iloc[:,1:]
    results_int_permu = []
    results_ext_permu = []
    for permu in tqdm(range(no_permu)):
        Y_permu = np.copy(Y)
        np.random.shuffle(Y_permu)
        space = {'alpha': [0.1, 0.5, 1, 2, 3, 4, 5, 10]}
        cv_outer = KFold(n_splits=10, random_state=0, shuffle=True)
        outer_results = list()
        inner_results = list()
        for train_ix, test_ix in cv_outer.split(X):
            X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]
            y_train, y_test = pd.Series(Y_permu).iloc[train_ix], pd.Series(Y_permu).iloc[test_ix]
            cv_inner = KFold(n_splits=5, random_state=0, shuffle=True)
            model = Lasso(random_state=0)
            # define search
            search = GridSearchCV(model, space, scoring='r2', cv=cv_inner, refit=True)
            # execute search
            result = search.fit(X_train, y_train)
            # get the best performing model fit on the whole training set
            best_model = result.best_estimator_
            #best_score_: Mean cross-validated score of the best_estimator
            inner_results.append(result.best_score_)
            # evaluate model on the hold out dataset, get the R2 of the best_estimator
            yhat = best_model.predict(X_test)
            # evaluate the model, R2
            r2 = sklearn.metrics.r2_score(y_test, yhat)
            # store the result
            outer_results.append(r2)
        # summarize the estimated performance of the model
        results_int_permu.append(np.mean(inner_results))
        results_ext_permu.append(np.mean(outer_results))
        #store the information to the dataframe
        svm_permu_file.loc[len(svm_permu_file.index)] = [np.mean(inner_results),np.mean(outer_results)]
        svm_permu_file.to_csv("lasso_permutation_collections_selfesteem.csv")
    
    p_int = (sum([i > inner_mean for i in results_int_permu])+1) / (no_permu+1)
    p_ext = (sum([i > outer_mean for i in results_ext_permu])+1) / (no_permu+1)
        
    return [results_int_permu, results_ext_permu, p_int, p_ext]

def get_permutation_p_classification(no_permu,roc_ls_mean,X,Y):
    #used to store the permutation information
    svm_permu_file = pd.read_csv("15svm_permutation_collections.csv")
    if len(svm_permu_file.columns) > 2:
        svm_permu_file = svm_permu_file.iloc[:,1:]
    #to store the roc auc permu
    roc_auc_ls_permu = []
    for permu in tqdm(range(no_permu)):
        Y_permu = np.copy(Y)
        np.random.shuffle(Y_permu)
        if permu%5 == 0:
            time.sleep(5)
        #roc,accuracy,sensitivity,specificity
        roc_permu_ls, _, _, _ = kfold(X,pd.Series(Y_permu))
        roc_auc_ls_permu.append(np.mean(roc_permu_ls))
        #store the information to the dataframe
        svm_permu_file.loc[len(svm_permu_file.index)] = [X.columns, np.mean(roc_permu_ls)]
        svm_permu_file.to_csv(str(len(X.columns))+"svm_permutation_collections.csv")

    p_value = (sum(roc_ls_mean < roc_auc_ls_permu)+1) / (no_permu+1)
    
    return p_value

#if get_permutation_p_classification always stuck
def per_get_permutation_p_classification(X,Y):
    svm_permu_file = pd.read_csv("15svm_permutation_collections.csv")
    if len(svm_permu_file.columns) > 2:
        svm_permu_file = svm_permu_file.iloc[:,1:]
    Y_permu = np.copy(Y)
    np.random.shuffle(Y_permu)
    #roc,accuracy,sensitivity,specificity
    roc_permu_ls, _, _, _ = kfold(X,pd.Series(Y_permu))
    #store the information to the dataframe
    svm_permu_file.loc[len(svm_permu_file.index)] = [X.columns, np.mean(roc_permu_ls)]
    svm_permu_file.to_csv(str(len(X.columns))+"svm_permutation_collections.csv")
